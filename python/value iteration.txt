%reset
import numpy as np
import psycopg2

## read data form database 
conn = psycopg2.connect("dbname=postgres user=postgres")
cur = conn.cursor()
cur.execute("SELECT * from ecoracer_learning_ps_table;")
psdb = cur.fetchall()
#this could be reduced reading times for exploration
cur.execute("SELECT count(*) from ecoracer_learning_ps_table where id>0;")
init_state_size = cur.fetchall()[0][0]

## define class for state
class State:
    def __init__(self,dbdata):
        self.speed = dbdata[0]
        self.time = dbdata[1]
        self.slope = dbdata[2]
        self.distance = dbdata[3]
    def myprint(self):
        print('state:',[self.speed,self.time,self.slope,self.distance])
## define class for tuple        
class Tuple:
    def __init__(self,dbdata):
        self.state_ini = State([dbdata[1],dbdata[2],dbdata[3],dbdata[4]])
        self.act = dbdata[5]
        self.reward = dbdata[6] 
        self.state_end = State([dbdata[7],dbdata[8],dbdata[9],dbdata[10]])       
    def myprint(self):
        self.state_ini.myprint()
        print('act/reward:',[self.act,self.reward])
        self.state_end.myprint()
#         self.winning_end = db_data[11]
#         self.used = db_data[12]
#         self.initial = db_data[13]
#         self.playID = db_data[14]

# tuples for both human demonstration and exploration
tuples = []
for dbdata in psdb: 
    tuples.append(Tuple(dbdata))
assert (len(tuples) == init_state_size),"Error in storing database!"

## parameters for value iteration
alpha = 0.01 #discount rate
gamma = 0.1 #learning rate
state_width=4 #four elements in each state
V = np.zeros((init_state_size,state_width))
PI = np.zeros((init_state_size,state_width))
sigma = 100

# initial Value function and optimal policy
VP = {}
for tuplei in tuples:
    VP[tuplei.state_ini] = [0,False]
    VP[tuplei.state_end] = [0,False]

# looping for value iteration
cnt = 0;
while True:
    for tuplei in tuples:
#         tuplei.myprint()
        # PROBLEM HERE! v_prim don't know, should be state_end after action
        V_prim = VP[tuplei.state_end][0];
        V = VP[tuplei.state_ini][0];
        sigma = tuplei.reward + gamma * V_prim  - V
        if (gamma>0):
            VP[tuplei.state_ini] = [V + alpha * gamma, True]
        else:
            VP[tuplei.state_ini] = [V + alpha * (V_prim - V), False]
    cnt = cnt + 1
    print(cnt,sigma)
    if (sigma<1e-3):
        break
        
cur.close()

## write result of value iteration to database
con = psycopg2.connect("dbname='postgres' user='postgres'")   
cur = con.cursor()

#current size
cur.execute("SELECT COUNT(*) FROM ecoracer_learning_ps_value_table; ")
vtable_size = cur.fetchall()[0][0]

#Append those new items to Vaule table
for count, (state,vp) in enumerate(VP.iteritems(), start=1+vtable_size):
    cur.execute("INSERT INTO ecoracer_learning_ps_value_table VALUES ( %s, %s, %s, %s, %s, %s, %s )"\
                , (count,state.speed,state.time,state.slope,state.distance,vp[0],vp[1],))

    
con.commit()
cur.close()